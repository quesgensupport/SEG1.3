---
title: "SEG Shiny Heatmap (version 1.3)"
author: "Martin Frigaard"
output: github_document
---


```{r setup, include=FALSE}
require(tidyverse)
require(mosaic)
require(magrittr)
library(knitr)
library(rmdformats)
## Global options
options(max.print = "75")
knitr::opts_chunk$set(
  size = "small",
  cache = FALSE,
  prompt = FALSE,
  tidy = FALSE,
  comment = NA,
  message = FALSE,
  warning = FALSE
)
opts_knit$set(width = 75)
```


**PACKAGES:**  

```{r packages_functions, message=FALSE, warning=FALSE}
library(dplyr) # Data wrangling, glimpse(50) and tbl_df().
library(ggplot2) # Visualise data.
library(lubridate) # Dates and time.
library(readr) # Efficient reading of CSV data.
library(stringr) # String operations.
library(tibble) # Convert row names into a column.
library(tidyr) # Prepare a tidy dataset, gather().
library(magrittr) # Pipes %>%, %T>% and equals(), extract().
library(tidyverse) # all tidyverse packages
library(mosaic) # favstats and other summary functions
library(fs) # file management functions
library(shiny) # apps
# custom function ----
num_vars_summ <- function(df, expr) {
  expr <- enquo(expr) # turns expr into a quosure
  summarise(df,
    n = sum((!is.na(!!expr))), # non-missing
    na = sum((is.na(!!expr))), # missing
    mean = mean(!!expr, na.rm = TRUE), # unquotes mean()
    median = median(!!expr, na.rm = TRUE), # unquotes median()
    sd = sd(!!expr, na.rm = TRUE), # unquotes sd()
    variance = var(!!expr, na.rm = TRUE), # unquotes var()
    min = min(!!expr, na.rm = TRUE), # unquotes min()
    max = max(!!expr, na.rm = TRUE), # unquotes max()
    se = sd / sqrt(n)
  ) # standard error
}
```

**HEADER:**  

* **Created date:** `r Sys.Date()`    
* **R version:** `r R.version.string`   


# Motivation

Re-create the heatmap image below into a shiny app.

![SEG_n2083](./Image/SEG_n2083.png)

```{r SEG_n2083}
# fs::file_show("./Image")
```


Previous data inputs. 

```{r data_inputs, eval=FALSE}
# 1 - DEFINE DATA INPUTS ============= ----
# define the root github raw
github_root <- "https://raw.githubusercontent.com/"
# 1.1 Load and wrangle the risk pair data ---- ---- ----
riskpair_repo <- "mjfrigaard/SEG_shiny/master/Data/RiskPairData.csv"
# load this from web
RiskPairData <- read_csv(paste0(github_root, riskpair_repo))
# Make sure the names in the RiskPairData data frame are identical
# to the names in SampMeasData
# 1.2 create absolute value of RiskFactor ---- ---- ----
RiskPairData <- RiskPairData %>%
  dplyr::mutate(abs_risk = abs(RiskFactor))
# 1.3 reorganize columns in RiskPairData ---- ---- ---- ----
RiskPairData <- RiskPairData %>%
  dplyr::select(
    RiskPairID,
    REF = RefVal,
    BGM = MeasVal,
    everything()
  )
# this is what our RiskPairData data frame looks like...
# Observations: 361,201
# Variables: 5
# $ RiskPairID <int> ...
# $ REF        <int> ...
# $ BGM        <int> ...
# $ RiskFactor <dbl> ...
# $ abs_risk   <dbl> ...

# 1.4 export AppRiskPairData.csv  ---- ---- ---- ----
write_csv(
  as_data_frame(RiskPairData),
  "Data/app_data/AppRiskPairData.csv"
)

# 1.6 Load look-up table data  ---- ---- ---- ---- ----
# lookup table repo
lookup_repo <- "mjfrigaard/SEG_shiny/master/Data/LookUpRiskCat.csv"
LookUpRiskCat <- read_csv(paste0(github_root, lookup_repo))
# 1.7 rename RiskCatLabel, remove RiskCatRangeTxt -----
LookUpRiskCat <- LookUpRiskCat %>%
  dplyr::select(
    risk_cat = RiskCat,
    ABSLB,
    ABSUB
  )

# 1.8 export AppLookUpRiskCat.csv
# this is the data needed for the app, and needs to be uploaded to github:
write_csv(
  as_data_frame(LookUpRiskCat),
  "Data/app_data/AppLookUpRiskCat.csv"
)
```

## PART 1 - Download data inputs

There are three data sets that need to be loaded from Github. The following code goes into the `Code/helpers.R` file:

### 1.5 upload AppRiskPairData.csv from github

This uploads a wrangled data set into the app for risk pairs.

### 1.9 load the AppLookUpRiskCat.csv from github

This uploads a wrangled data set into the app for a look-up table

### 1.10 import full sample data set from github

This loads the full sample data file from Vanderbilt. 

### 1.11 create sample (SampMeasData)

This is the sample data set used for the app development. 


```{r AppData}
# define the root github raw
github_root <- "https://raw.githubusercontent.com/"
# 1.5 upload AppRiskPairData.csv from github  ---- ---- ---- ----
app_riskpair_repo <- "mjfrigaard/SEG_shiny/master/Data/AppRiskPairData.csv"
RiskPairData <- read_csv(paste0(github_root, app_riskpair_repo))
# RiskPairData %>% glimpse(20)
# this is what the data frame should look like:
# Observations: 361,201
# Variables: 5
# $ RiskPairID <int> ...
# $ REF        <int> ...
# $ BGM        <int> ...
# $ RiskFactor <dbl> ...
# $ abs_risk   <dbl> ...

# 1.9 load the AppLookUpRiskCat.csv from github  ---- ---- ---- ---- ----
app_lookup_repo <- "mjfrigaard/SEG_shiny/master/Data/AppLookUpRiskCat.csv"
LookUpRiskCat <- read_csv(paste0(github_root, app_lookup_repo))
# LookUpRiskCat %>% glimpse(30)
# this is what the data frame should look like:
# Observations: 8
# Variables: 3
# $ risk_cat <int> 0, 1, 2,...
# $ ABSLB    <dbl> -0.001, ...
# $ ABSUB    <dbl> 0.5, 1.0...

# 1.10 import full sample data set from github ---- ---- ---- ---- ----
full_sample_repo <- "mjfrigaard/SEG_shiny/master/Data/FullSampleData.csv"
SampleData <- read_csv(paste0(github_root, full_sample_repo))

# 1.11 create sample (SampMeasData) ---- ---- ---- ---- ----
SampMeasData <- SampleData %>% sample_n(., size = 2000)
# 1.12 create test data frame to export
AppTestData <- SampleData %>% sample_n(., size = 3000)
write_csv(
  as_data_frame(AppTestData),
  "Data/app_data/AppTestData.csv"
)
# 1.13 remove AppTestData/SampleData to avoid confusion! ---- ---- ---- ----
rm(SampleData, AppTestData)
# SampMeasData %>% names()
# [1] "BGM" "REF"
```

## PART 2 - Prepare the uploaded data file

We can assume from this point forward that `SampMeasData` is the imported data frame the user will upload. All changes to this data frame will need to be done as a 'reactive expression', meaning the input will change every time a new data set it uploaded. 

All of this code needs to be in the `app.R` file.

```{r prepare_data}
# 2 - PREPARE UPLOADED DATA FILE  ============= ----
# 2.1 add id column to imported data ----
SampMeasData <- SampMeasData %>%
  tibble::rowid_to_column(., "id") # we don't use the id, so don't add it to
# prepare_csv function

# SampMeasData %>% glimpse(30)
# this is what you should see:
# Observations: 2,000
# Variables: 2
# $ BGM <int> 107, 330, 156...
# $ REF <int> 109, 345, 155...

# 2.2 create SEG_pair_type ---- ----  ---- ----  ---- ----  ---- ----  ----
SampMeasData <- SampMeasData %>%
  dplyr::mutate(
    SEG_pair_type =
      dplyr::case_when(
        BGM > 600 ~ "out of range",
        REF > 600 ~ "out of range",
        BGM <= 20 ~ "out of range",
        REF <= 20 ~ "out of range",
        REF > BGM ~ "BGM below ref",
        REF < BGM ~ "BGM above ref",
        BGM == REF ~ "BGM equal to ref"
      )
  )
# SampMeasData %>% glimpse(30)
# this is what you should see:
# Observations: 2,000
# Variables: 3
# $ BGM           <int> 107...
# $ REF           <int> 109...
# $ SEG_pair_type <chr> "BG...
# 2.3 Join RiskPairData data to SampMeasData data ---- ----  ---- ----  ----
SampMeasData <- inner_join(
  x = SampMeasData,
  y = RiskPairData,
  by = c("BGM", "REF")
)
# SampMeasData %>% glimpse(30)
# this is what you should see:
# Observations: 1,993
# Variables: 6
# $ BGM           <int> 107...
# $ REF           <int> 109...
# $ SEG_pair_type <chr> "BG...
# $ RiskPairID    <int> 644...
# $ RiskFactor    <dbl> 0.0...
# $ abs_risk      <dbl> 0.0...

# 2.4 Create risk_cat variable ---- ---- ---- ---- ---- ---- ---- ----
# based on absolute value of risk factor
SampMeasData <- SampMeasData %>%
  dplyr::mutate(
    risk_cat =
      base::findInterval(
        x = abs_risk, # the abs_risk absolute value
        vec = LookUpRiskCat$ABSLB, # the lower bound absolute risk
        left.open = TRUE
      ) - 1
  )
# 2.5 Join SampMeasData data to LookUpRiskCat data ---- ----  ---- ----
SampMeasData <- SampMeasData %>%
  dplyr::inner_join(
    y = LookUpRiskCat, # inner join to look-up
    by = "risk_cat"
  )
# SampMeasData %>% group_by(risk_cat) %>%
#     num_vars_summ(abs_risk)
# 2.6 create pairtype_gt600, pairtype_lt21, pair_type ---- ----  ---- ----
SampMeasData <- SampMeasData %>%
  dplyr::mutate(
    # excluded over 600
    pairtype_gt600 = dplyr::case_when(
      REF > 600 ~ "REF > 600",
      TRUE ~ NA_character_
    ),
    # excluded under 21
    pairtype_lt21 = dplyr::case_when(
      REF < 21 ~ "REF < 21",
      TRUE ~ NA_character_
    ),
    # these are three general categories
    pair_type = dplyr::case_when(
      BGM < REF ~ "BGM < REF",
      BGM == REF ~ "BGM = REF",
      BGM > REF ~ "BGM > REF",
      TRUE ~ NA_character_
    )
  )
# SampMeasData %>% count(SEG_pair_type, pair_type) %>%
#     spread(pair_type, n)
#     This is correct, but SEG_pair_type includes an "out of range"
#     category.
# 2.7 create the risk cat text variable ---- ----  ---- ----  ---- ----
SampMeasData <- SampMeasData %>%
  dplyr::mutate(
    risk_cat_txt =
      dplyr::case_when(
        abs_risk < 0.5 ~ "None",
        abs_risk >= 0.5 & abs_risk <= 1 ~ "Slight, Lower",
        abs_risk > 1 & abs_risk <= 1.5 ~ "Slight, Higher",
        abs_risk > 1.5 & abs_risk <= 2.0 ~ "Moderate, Lower",
        abs_risk > 2 & abs_risk <= 2.5 ~ "Moderate, Higher",
        abs_risk > 2.5 & abs_risk <= 3.0 ~ "Severe, Lower",
        abs_risk > 3.0 & abs_risk <= 3.5 ~ "Severe, Higher",
        abs_risk > 3.5 ~ "Extreme"
      )
  )
# SampMeasData %>% group_by(risk_cat_txt) %>% num_vars_summ(abs_risk)
# 2.8 format REF and BGM as double ---- ----  ---- ----  ---- ----
SampMeasData$REF <- as.double(SampMeasData$REF)
SampMeasData$BGM <- as.double(SampMeasData$BGM)
```


## PART 3 - Calculate MARD, ISO difference, and ISO range

This recreates the summary statistics in the excel sheet sent to Vanderbilt.

```{r calculate_summary_stats}
# 3 - CALCULATE SUMMARY STATS  ============= ----
# 3.1 create relative diff/absolute relative diff variables ---- ----
SampMeasData <- SampMeasData %>%
  mutate(
    rel_diff = (BGM - REF) / REF, # relative diff
    abs_rel_diff = abs(rel_diff)
  ) # abs relative diff

# 3.2 create squared relative diff variable ---- ---- ---- ---- ---- ----
SampMeasData <- SampMeasData %>%
  mutate(sq_rel_diff = rel_diff^2)

# 3.3 create iso_diff variable ---- ---- ---- ---- ---- ---- ---- ---- ----
SampMeasData <- SampMeasData %>%
  dplyr::mutate(
    iso_diff =
      if_else(REF >= 100, # condition 1
        100 * abs(BGM - REF) / REF, # T 1
        if_else(REF < 100, # condition 2
          abs(BGM - REF), # T 2
          NA_real_
        ), # F 2
        NA_real_
      )
  ) # F 1

# 3.4 create iso range variable ---- ---- ---- ---- ---- ---- ---- ---- ----
SampMeasData <- SampMeasData %>%
  dplyr::mutate(
    iso_range =
      dplyr::case_when(
        iso_diff <= 5 ~ "<= 5% or 5 mg/dL",
        iso_diff > 5 & iso_diff <= 10 ~ "> 5 - 10% or mg/dL",
        iso_diff > 10 & iso_diff <= 15 ~ "> 10 - 15% or mg/dL",
        iso_diff > 15 & iso_diff ~ "> 15% or 15 mg/dL"
      )
  )
```

### Create function for PART 2 & 3

Parts 2 and 3 needs to be in a function, like the one below:

```{r clean_weather, eval=FALSE}
# Finish the clean_weather function
clean_weather <- function(file) {
  weather <- read.fwf(file,
    header = FALSE,
    col.names = c("month", "day", "year", "temp"),
    widths = c(14, 14, 13, 4)
  )
  weather %>%
    filter(!(month == 2 & day == 29)) %>%
    group_by(year) %>%
    mutate(yearday = 1:length(day)) %>%
    ungroup() %>%
    filter(temp != -99)
}
# there is a data file in the Data folder that this function will clean
# fs::dir_ls("Data/Raw") %>% writeLines()
clean_weather("Data/Raw/NYNEWYOR.txt") %>% glimpse(30)
```

This app needs a helper function that takes 1) an uploaded .csv file, 2) wrangles this .csv file by adding a few variables, joining to `RiskPairData` and `LookUpRiskCat`, and 3) calculating the variables for the MARD, binomial test, etc. 

```{r prepare_csv}
prepare_csv <- function(file) {
  # 0.1 - import data frame ----
  SampMeasData <- readr::read_csv(file,
    col_types =
      cols(
        BGM = col_double(),
        REF = col_double()
      )
  )
  # 0.2.2 create SEG_pair_type ---- ----  ---- ----  ---- ----  ---- ----
  SampMeasData %>%
    dplyr::mutate(
      SEG_pair_type = dplyr::case_when(
        BGM > 600 ~ "out of range",
        REF > 600 ~ "out of range",
        BGM <= 20 ~ "out of range",
        REF <= 20 ~ "out of range",
        REF > BGM ~ "BGM below ref",
        REF < BGM ~ "BGM above ref",
        BGM == REF ~ "BGM equal to ref"
      ) # 0.2.3 Join RiskPairData data to SampMeasData data ---- ----  ----
    ) %>%
    dplyr::inner_join(.,
      y = RiskPairData,
      by = c("BGM", "REF")
    ) %>%
    dplyr::mutate( # 0.2.4 Create risk_cat variable ---- ---- ---- ---- ----
      risk_cat =
        base::findInterval(
          x = abs_risk, # the abs_risk absolute value
          vec = LookUpRiskCat$ABSLB, # the lower bound absolute risk
          left.open = TRUE
        ) - 1
    ) %>%
    dplyr::inner_join( # 0.2.5 Join to LookUpRiskCat data ---- ----  ----
      x = ., y = LookUpRiskCat, # inner join to look-up
      by = "risk_cat"
    ) %>%
    dplyr::mutate( # 0.2.6 create pairtypes ---- ----
      # excluded over 600
      pairtype_gt600 = dplyr::case_when(
        REF > 600 ~ "REF > 600",
        TRUE ~ NA_character_
      ),
      # create excluded under 21
      pairtype_lt21 = dplyr::case_when(
        REF < 21 ~ "REF < 21",
        TRUE ~ NA_character_
      ),
      # create pair_type
      pair_type = dplyr::case_when(
        BGM < REF ~ "BGM < REF",
        BGM == REF ~ "BGM = REF",
        BGM > REF ~ "BGM > REF",
        TRUE ~ NA_character_
      )
    ) %>%
    dplyr::mutate( # 0.2.7 create the risk cat text variable ---- ----  ----
      risk_cat_txt = # text risk categories
      dplyr::case_when(
        abs_risk < 0.5 ~ "None",
        abs_risk >= 0.5 & abs_risk <= 1 ~ "Slight, Lower",
        abs_risk > 1 & abs_risk <= 1.5 ~ "Slight, Higher",
        abs_risk > 1.5 & abs_risk <= 2.0 ~ "Moderate, Lower",
        abs_risk > 2 & abs_risk <= 2.5 ~ "Moderate, Higher",
        abs_risk > 2.5 & abs_risk <= 3.0 ~ "Severe, Lower",
        abs_risk > 3.0 & abs_risk <= 3.5 ~ "Severe, Higher",
        abs_risk > 3.5 ~ "Extreme"
      )
    ) %>%
    dplyr::mutate( # 0.3.1, 0.3.2 create MARD variables ----- -----
      rel_diff = (BGM - REF) / REF, # relative diff
      abs_rel_diff = abs(rel_diff), # abs relative diff
      sq_rel_diff = rel_diff^2,
      iso_diff = # 0.3.3 create iso_diff variable ---- ---- ---- ----
      if_else(REF >= 100, # condition 1
        100 * abs(BGM - REF) / REF, # T 1
        if_else(REF < 100, # condition 2
          abs(BGM - REF), # T 2
          NA_real_
        ), # F 2
        NA_real_
      ), # F1
      iso_range = dplyr::case_when( # 0.3.4 create iso range variable ----
        iso_diff <= 5 ~ "<= 5% or 5 mg/dL",
        iso_diff > 5 & iso_diff <= 10 ~ "> 5 - 10% or mg/dL",
        iso_diff > 10 & iso_diff <= 15 ~ "> 10 - 15% or mg/dL",
        iso_diff > 15 & iso_diff ~ "> 15% or 15 mg/dL"
      )
    )
}
```


Now we can test this function with some sample data drawn from the github repo. 

```{r test_data_for_prepare_csv}
full_sample_repo <- "mjfrigaard/SEG_shiny/master/Data/FullSampleData.csv"
SampleData <- read_csv(paste0(github_root, full_sample_repo))
# 0.3.5 create data frame to test prepare_csv() ----
AppTestDataSmall <- SampleData %>% sample_n(., size = 1000)
write_csv(
  as_data_frame(AppTestDataSmall),
  "Data/app_data/AppTestDataSmall.csv"
)
AppTestDataMed <- SampleData %>% sample_n(., size = 2000)
write_csv(
  as_data_frame(AppTestDataMed),
  "Data/app_data/AppTestDataMed.csv"
)
AppTestDataBig <- SampleData %>% sample_n(., size = 3000)
write_csv(
  as_data_frame(AppTestDataBig),
  "Data/app_data/AppTestDataBig.csv"
)
```

Now test this with three different size data frames. 

```{r test_prepare_csv}
# 0.3.6 test prepare_csv with small data set ----
prepare_csv("Data/app_data/AppTestDataSmall.csv") %>% glimpse(78)
# 0.3.7 test prepare_csv with med data set ----
prepare_csv("Data/app_data/AppTestDataMed.csv") %>% glimpse(78)
# 0.3.8 test prepare_csv with big data set ----
prepare_csv("Data/app_data/AppTestDataBig.csv") %>% glimpse(78)
```


## PART 4 - Create result tables 

This creates the objects from the calculations above.

```{r tables_summary_stats}
# use new function
SampMeasData <- prepare_csv("Data/app_data/AppTestDataBig.csv")
# 4 - DEFINE RESULTS TABLES  ============= ----
## 4.1 pair_type Table ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
pair_type <- SampMeasData %>%
  dplyr::count(pair_type) %>%
  dplyr::rename(`pair type` = pair_type)

## 4.2 Excluded from SEG Analysis ---- ---- ---- ---- ---- ---- ---- ----
excluded <- SampMeasData %>%
  dplyr::count(
    pairtype_gt600,
    pairtype_lt21
  ) %>%
  dplyr::rename(
    `REF greater than 600` = pairtype_gt600,
    `REF less than 21` = pairtype_lt21,
    Total = n
  )
## 4.3 Summary table  ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
summary_table <- data.frame(
  Total = c(nrow(SampMeasData)),
  Bias = c(mean(SampMeasData$rel_diff)),
  MARD = c(mean(SampMeasData$abs_rel_diff)),
  CV = c(sd(SampMeasData$rel_diff)), stringsAsFactors = FALSE, 
                                                    check.names = FALSE) %>%
    add_column(
            `Lower 95% Limit of Agreement` = .$Bias - 1.96 * .$CV) %>%
    add_column(
        `Upper 95% Limit of Agreement` = .$Bias + 1.96 * .$CV) %>%
        dplyr::mutate(
            Bias = base::paste0(base::round(
                100 * Bias, 1), "%"),
            MARD = base::paste0(base::round(
                100 * MARD, 1), "%"),
            CV = base::paste0(base::round(
                100 * CV, 1), "%"))



## 4.4 clinical table ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
clinical <- SampMeasData %>%
  dplyr::group_by(risk_cat_txt) %>%
  dplyr::summarise(`Number of Pairs` = n()) %>%
  dplyr::mutate(
    Percent =
      paste0(round(100 * `Number of Pairs` / sum(`Number of Pairs`), 1), "%")
  ) %>%
  dplyr::arrange(desc(`Number of Pairs`)) %>%
  dplyr::rename(`Risk Category` = risk_cat_txt)

# 4.5 study_criteria_table table  ---- ---- ---- ---- ---- ---- ----
study_criteria_table <- SampMeasData %>%
  dplyr::group_by(iso_range) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(
    Percent =
      paste0(round(100 * n / sum(n), 1), "%")
  ) %>%
  dplyr::arrange(desc(n)) %>%
  dplyr::rename(`ISO range` = iso_range)

# 4.6 Binomial Test table ---- ---- ---- ---- ---- ---- ----
#           create successes
#               Failures will be in the '>=15% or 15 mg/dL' category of
#               iso_range--subtract from total to get successes

successes <- nrow(SampMeasData) - base::nrow(
  dplyr::filter(
    SampMeasData,
    iso_range == "> 15% or 15 mg/dL"
  )
)

#           create trials
trials <- nrow(SampMeasData)
#               trials could also be the number of rows in the total
#               data frame (with out of range values)
#           create probability
prb <- 0.95
#           create criterion
crit <- 0.05
#           create test data frame
BinomialTest <- broom::tidy(binom.test(
  x = successes,
  n = trials,
  p = prb,
  conf.level = 0.95
))

# Results tables ---- ---- ---- ---- ---- ---- ----
# These are the tables for the shiny app
knitr::kable(pair_type)
knitr::kable(excluded)
knitr::kable(study_criteria_table)
knitr::kable(clinical)
knitr::kable(study_criteria_table)
knitr::kable(BinomialTest)
```

All but the `BinomialTest` table will work in app with `isolate()` function. The `BinomialTest` needs to be a function. 

```{r binomial_tbl, eval=TRUE}
SampMeasDataBig <- prepare_csv("Data/app_data/AppTestDataBig.csv")
binomial_tbl <- function(dataset) {
  successes <- nrow(dataset) - (filter(
    dataset,
    iso_range %in% "> 15% or 15 mg/dL"
  )) %>% nrow()
  trials <- nrow(dataset)
  # create probability
  prb <- 0.95
  # create criterion
  broom::tidy(binom.test(
    x = successes,
    n = trials,
    p = prb,
    conf.level = 0.95
  ))
}
# there is a data file in the Data folder that this function will clean
binomial_tbl(SampMeasDataBig)
```



## PART 5 - Heatmap 

Now we are ready to re-create the heatmap (using the wrangled data)

```{r 5-heatmap_plot.R}
# 5 - HEAT MAP DATA INPUTS ============= ----
#
# 5.0 upload AppRiskPairData.csv from github  ---- ---- ---- ----
# app_riskpair_repo <- "mjfrigaard/SEG_shiny/master/Data/AppRiskPairData.csv"
# RiskPairData <- read_csv(paste0(github_root, app_riskpair_repo))
#
# 5.1 mmol conversion factor ---- ---- ---- ---- ---- ---- ----
mmolConvFactor <- 18.01806

# 5.2 rgb2hex function ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
# This is the RGB to Hex number function for R
rgb2hex <- function(r, g, b) rgb(r, g, b, maxColorValue = 255)

# 5.3 risk factor colors ---- ---- ---- ---- ---- ---- ---- ---- ----
# These are the values for the colors in the heatmap.
abs_risk_0.0000_color <- rgb2hex(0, 165, 0)
# abs_risk_0.0000_color
abs_risk_0.4375_color <- rgb2hex(0, 255, 0)
# abs_risk_0.4375_color
abs_risk_1.0625_color <- rgb2hex(255, 255, 0)
# abs_risk_1.0625_color
abs_risk_2.7500_color <- rgb2hex(255, 0, 0)
# abs_risk_2.7500_color
abs_risk_4.0000_color <- rgb2hex(128, 0, 0)
# abs_risk_4.0000_color
riskfactor_colors <- c(
  abs_risk_0.0000_color,
  abs_risk_0.4375_color,
  abs_risk_1.0625_color,
  abs_risk_2.7500_color,
  abs_risk_4.0000_color
)

# 5.4 create base_data data frame ---- ---- ---- ---- ---- ---- ---- ----
base_data <- data.frame(
  x_coordinate = 0,
  y_coordinate = 0,
  color_gradient = c(0:4)
)

# 5.5 base layer ---- ---- ---- ---- ---- ---- ---- ----
base_layer <- ggplot() +
  geom_point(
    data = base_data, # defines data frame
    aes(
      x = x_coordinate,
      y = y_coordinate,
      fill = color_gradient
    )
  ) # + # uses x, y, color_gradient
# 5.6 risk pair data layer  ---- ---- ---- ---- ---- ---- ---- ----
# RiskPairData %>% glimpse(78)
risk_layer <- base_layer +
  geom_point(
    data = RiskPairData, # new data set
    aes(
      x = REF, # additional aesthetics from new data set
      y = BGM,
      color = abs_risk
    ),
    show.legend = FALSE
  )
# 5.7 add fill gradient  ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
risk_layer_gradient <- risk_layer +
  ggplot2::scale_fill_gradientn( # scale_*_gradientn creats a n-color gradient
    values = scales::rescale(c(
      0, # darkgreen
      0.4375, # green
      1.0625, # yellow
      2.75, # red
      4.0
    )), # brown
    limits = c(0, 4),
    colors = riskfactor_colors,
    guide = guide_colorbar(
      ticks = FALSE,
      barheight = unit(100, "mm")
    ),
    breaks = c(
      0.25,
      1,
      2,
      3,
      3.75
    ),
    labels = c(
      "none",
      "slight",
      "moderate",
      "high",
      "extreme"
    ),
    name = "risk level"
  )

# 5.8 add color gradient  ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
# Add the new color scales to the scale_y_continuous()
heatmap_plot <- risk_layer_gradient +
  ggplot2::scale_color_gradientn(
    colors = riskfactor_colors, # these are defined above
    guide = "none",
    limits = c(0, 4),
    values = scales::rescale(c(
      0, # darkgreen
      0.4375, # green
      1.0625, # yellow
      2.7500, # red
      4.0000
    ))
  ) +
  ggplot2::scale_y_continuous(
    limits = c(0, 600),
    sec.axis =
      sec_axis(~. / mmolConvFactor,
        name = "measured blood glucose (mmol/L)"
      ),
    name = "measured blood glucose (mg/dL)"
  ) +
  scale_x_continuous(
    limits = c(0, 600),
    sec.axis =
      sec_axis(~. / mmolConvFactor,
        name = "reference blood glucose (mmol/L)"
      ),
    name = "reference blood glucose (mg/dL)"
  )
# 5.9 export plot template  ---- ---- ---- ---- ---- ---- ---- ---- ----
save(heatmap_plot, file = "Data/heatmap_plot.RData")
```

Now reload this plot. 

```{r heatmap_plot.RData}
# 5.10 reload plot ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
load("Data/heatmap_plot.RData")
heatmap_plot
```


Now we introduce the uploaded sample data frame (that has already been wrangled).

```{r heat_map_1.0}
# 5.11 add SampMeasData to heatmap_plot ---- ---- ---- ---- ---- ---- ----
# Add the data to heatmap_plot
heat_map_1.0 <- heatmap_plot +
  geom_point(
    data = SampMeasData, # introduce sample data frame
    aes(
      x = REF,
      y = BGM
    ),
    shape = 21,
    fill = "white",
    size = 1.2,
    stroke = 1
  )
heat_map_1.0
```

Export the file as .png

```{r ggsave_heat_map_1.0}
# 5.9 export plot as heat_map_1.0 ---- ---- ---- ---- ---- ---- ---- ----
ggsave(
  filename = paste0(
    "Image/", # location
    "heat_map_1.0-", # file name
    noquote(Sys.Date()), # date
    ".png"
  ), # extension
  dpi = 320
)
```


## PART 6 - Modified Bland-Altman

Load data and functions. 

```{r source_prepare_csv.R}
# fs::dir_ls("Code")
source("Code/prepare_csv.R")
SampMeasDataBig <- prepare_csv("Data/app_data/AppTestDataBig.csv")
SampMeasDataBig %>% glimpse(78)
```

The `SampMeasDataBig` file represents what the data will look like in the app when they have been uploaded. 

![mod_bland_altman.png](Image/mod_bland_altman.png)

I will create the modified bland-altman plot above with ggplot2.

These data add the reference lines to the plot. 

```{r SEGBlandAltmanRefVals}
github_root <- "https://raw.githubusercontent.com/"
ba_ref_repo <- "mjfrigaard/SEG_shiny/master/Data/APPSEGBlandAltmanRefVals.csv"
SEGBlandAltmanRefVals <- read_csv(paste0(github_root, ba_ref_repo))
SEGBlandAltmanRefVals
```

They will go in the `helpers.R` file.

The modified bland altman plot in excel uses the LN of the REF and BGM values. I calculate these on the fly before mapping to aesthetics. 

```{r mod_ba_plot_1.0}
mod_ba_plot_1.0 <- SampMeasDataBig %>%
  dplyr::mutate( # calculate LN of REF and BGM 
    lnREF = log(REF),
    lnBGM = log(BGM),
    lnDiff = lnBGM - lnREF,
    rel_perc_diff = exp(lnDiff) - 1
  ) %>%
  ggplot2::ggplot(aes(x = REF, y = rel_perc_diff)) +
  ggplot2::geom_point(alpha = 0.5, color = "royalblue") +
  ggplot2::scale_y_continuous(
    name = "% Error",
    limits = c(-0.50, 0.50)
  ) +
  ggplot2::geom_line(aes(x = Ref, y = UB),
    data = SEGBlandAltmanRefVals,
    linetype = "dotted",
    color = "red",
    size = 1.5
  ) +
  ggplot2::geom_line(aes(x = Ref, y = LB),
    data = SEGBlandAltmanRefVals,
    linetype = "dotted",
    color = "red",
    size = 1.5
  ) +
  ggplot2::labs(
    x = "Reference (mg/dL)",
    title = "Modified Bland-Altman Plot",
    subtitle = "Blood Glucose Monitoring System Surveillance Program"
  )
mod_ba_plot_1.0
ggsave(filename = "Image/mod_ba_plot_1.0.png")
```

This was added as a possible download to version 1.1.






**FOOTER:**

```{r session_info, echo=TRUE}
devtools::session_info() # put this at the end of document
```
